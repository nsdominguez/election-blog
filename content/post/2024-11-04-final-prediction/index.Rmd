---
title: "FINAL PREDICTION"
author: "Nick Dominguez"
date: '2024-11-04'
slug: final-prediction
---

```{r, include = FALSE}
# set working directory
setwd("~/Documents/GOV 1347/GOV 1347/content/post/2024-11-04-final-prediction")
```

```{r, include = FALSE}
# load libraries
library(blogdown)
library(plotly)
library(ggthemes)
library(haven)
library(maps)
library(RColorBrewer)
library(scales)
library(sf)
library(spData)
library(stargazer)
library(tidygeocoder)
library(tidyverse)
library(tigris)
library(tmap)
library(tmaptools)
library(viridis)
library(rsample)
library(randomForest)
library(caret)
library(Metrics)
library(readr)
library(CVXR)
library(ranger)
library(purrr)
```

```{r, include = FALSE}
full_data <- read_csv("full_data.csv")
```

```{r, include = FALSE}
full_data <- full_data %>%
  mutate(weight = exp((year - 2020) / 4))

train <- full_data %>%
  filter(year < 2024 & year >= 1976)

test <- full_data %>%
  filter(year == 2024)

states_with_poll_data <- full_data %>%
  filter(year == 2024 & !is.na(poll_difference)) %>%
  select(state) %>%
  distinct() %>%
  inner_join(full_data, by = "state")

states_without_poll_data <- full_data %>%
  filter(!state %in% states_with_poll_data$state)

train_nopoll <- train %>%
  filter(!state %in% states_with_poll_data$state)

train_poll <- train %>%
  filter(state %in% states_with_poll_data$state)

test_nopoll <- test %>%
  filter(!state %in% states_with_poll_data$state)

test_poll <- test %>%
  filter(state %in% states_with_poll_data$state)

```


```{r, include = FALSE}
# Mod1 (poll state only)
mod.1 <- train_poll %>%
  group_by(state) %>%
  do(mod1 = lm(D_pv2p ~ poll_difference, data = ., weights = .$weight))

mod.1_pred <- test_poll %>%
  rowwise() %>%
  mutate(
    prediction = list(predict(
      mod.1$mod1[mod.1$state == state][[1]], 
      newdata = data.frame(poll_difference = poll_difference, year = 2024),
      interval = "prediction", level = 0.95
    )),
    pred.1 = prediction[1],
    lwr.1 = prediction[2],
    upr.1 = prediction[3]
  ) %>%
  select(state, pred.1, lwr.1, upr.1)

```

```{r, include = FALSE}
mean_adj_r_squared <- mod.1 %>%
  summarise(adj_r_squared = summary(mod1)$adj.r.squared) %>%
  summarise(mean_adj_r_squared = mean(adj_r_squared, na.rm = TRUE))
```

```{r, include = FALSE}
all_pred <- read_csv("all_pred.csv") %>%
  select(-year, -poll_difference, -pred.3, -lwr.3, -upr.3) %>%
  left_join(mod.1_pred)
```

```{r, include = FALSE}
mod_rf_data <- train %>%
  filter(year >= 2008)

rf_model <- randomForest(
  D_pv2p ~ white + black + american_indian + asian_pacific_islander + 
                       other_race + two_or_more_races + hispanic_white + hispanic_black + 
                       not_hispanic_white + under_18 + age_18_to_24 + age_25_to_34 + 
                       age_35_to_44 + age_45_to_54 + age_55_to_64 + age_65_to_74 + 
                       age_75_to_84 + age_85_and_over + less_than_college + 
                       bachelors + graduate + D_pv2p_lag1 + ur_avg + GDP_growth_quarterly + 
                       RDPI_growth_quarterly + CPI + inc_party.x + inc_prez_running + 
                       inc_party_duration + inc_party_nom_recent_admin + challenger_recent_admin + 
                       juneapp + D_pv2p_lag2 + D_contribution_prop + year, data = mod_rf_data, ntree = 1000,       
  mtry = 12,           
  importance = TRUE
)
```

# Final Prediction

**November 4, 2024** – It’s been a long time coming, but the moment we’ve been waiting for is here. Tomorrow is officially Election Day for the 2024 Presidential Election. Tomorrow, predictions become testable as we begin the multi-day process of counting millions of ballots. Therefore, it is officially time to release my final model, and my final predictions for the 2024 Presidential Election.

Since the beginning of September, I’ve constructed many models with a myriad of different variables to predict vote share. Now, I’ve landed upon what I believe to be an optimal model, or ensemble of models rather, to best predict the outcome of tomorrow’s election. 

First, I amassed my state predictions for some of my previous models: the economic fundamentals model, incumbency model, demographics model, FEC contributions model, as these all use various fundamental indicators and barometers of support to predict outcomes. Similar to last week, I updated my simple unpooled polling model using statewide averages of two days prior to Election Day using the difference in average polling between the Democrat and the Republican candidates to predict the Democrat’s two-party vote share, weighted exponentially by year. For the sake of brevity, I will not get into the minutiae of these previous models. More information about each of these models can be found in their respective blog posts in prior weeks. 

The newest addition to this week is a random forest model constructed of all variables I have used in my aforementioned models, except polling data, as this data is only available for certain states. The random forest model contains state demographic variables (race, age, education), lag vote share, state Q2 unemployment rate, national Q2 GDP growth, Q2 RDPI growth, and CPI; national president approval rating, incumbent indicators, the incumbent party’s duration in power, year, and state proportion of Democrat candidate FEC contributions. I chose to put all of these variables in a random forest model for a more robust prediction based on all of these factors that have been known to influence election outcomes, accounting for the complex relationships and interactions between these variables. This random forest model, built on data from as early 1976, has an in-sample RMSE of 1.27 and an cross-validation out-of-sample RMSE of 3.19. 

Using 2024 data from 2008-2020 (years in which all variables are present), I predicted Harris’ two-party vote share. Due to the structure of the random forest, I could not easily compute prediction intervals. Nevertheless, I used this data in my final ensemble model. Below, you can see which variables have the most explanatory power. It seems that lag vote share, FEC contributions (as a measure of enthusiasm), and a state’s percentage of college graduates are the most important predictors of election outcomes according to this model.



```{r, echo = FALSE}
varImpPlot(rf_model)
```

```{r, include = FALSE}
# merge all data 
all_pred$pred.rf <- predict(rf_model, newdata = test)
```

```{r, include = FALSE}
# In-Sample RMSE
in_sample_predictions <- predict(rf_model, newdata = mod_rf_data)
in_sample_rmse <- RMSE(in_sample_predictions, mod_rf_data$D_pv2p)
print(paste("In-Sample RMSE:", in_sample_rmse))

# Out-of-Sample RMSE using Cross-Validation
set.seed(123)  # For reproducibility
cv_control <- trainControl(method = "cv", number = 5)  # 5-fold CV

cv_model <- train(
  D_pv2p ~ white + black + american_indian + asian_pacific_islander + 
           other_race + two_or_more_races + hispanic_white + hispanic_black + 
           not_hispanic_white + under_18 + age_18_to_24 + age_25_to_34 + 
           age_35_to_44 + age_45_to_54 + age_55_to_64 + age_65_to_74 + 
           age_75_to_84 + age_85_and_over + less_than_college + 
           bachelors + graduate + D_pv2p_lag1 + ur_avg + GDP_growth_quarterly + 
           RDPI_growth_quarterly + CPI + inc_party.x + inc_prez_running + 
           inc_party_duration + inc_party_nom_recent_admin + challenger_recent_admin + 
           juneapp + D_pv2p_lag2 + D_contribution_prop + year, 
  data = mod_rf_data, 
  method = "rf",
  trControl = cv_control,
  tuneGrid = expand.grid(.mtry = 12),  # Match mtry with your model's parameters
  ntree = 1000
)

# Extract Out-of-Sample RMSE
out_of_sample_rmse <- cv_model$results$RMSE
print(paste("Out-of-Sample RMSE (Cross-Validation):", out_of_sample_rmse))
```

```{r, include = FALSE}
all_pred <- all_pred %>%
  select(-pred.7, -lwr.7, -upr.7)
```

I decided to aggregate this diverse set of random forest and OLS models to help make a more accurate final prediction. Since not all models are built the same, I used a weighted average. Ideally, I would weight the model predictions based on their out-of-sample predictive power. However, I was unable to calculate appropriate measurements for some of the models. Therefore, I created my own weighting scheme, emphasizing the Random Forest model because of its low error and robustness, the polling model, due to their ability to directly capture voter sentiment, the FEC contributions model, due to its high importance as shown above, and the economic fundamentals model due to the traditional importance of fundamentals. I downweighted the demographics model because this model had a high out-of-sample RMSE of 6.52 and the demographic data I have is simulated, not actual values. The weighting scheme is shown below. As mentioned earlier, not every state has polling data available in 2024, nor does every model have a computed confidence interval (such as the all-variable random forest), so state weighted average predictions and intervals are calculated from whatever data available.

```{r, echo = FALSE}
library(knitr)

# Create a data frame for the table
example_table <- data.frame(
  Variable = c("Economic Fundamentals", "Incumbency Factors", "Demographics", "FEC Contributions", "Polling Data", "All-Variable RF"),
  Weight = c(1.02, 1, 0.9, 1.01, 1.04, 1.05))

# Render the table using knitr::kable
kable(example_table, col.names = c("Model", "Weight"))
```


```{r, include = FALSE}
all_pred$avg_pred <- rowMeans(all_pred[, c("pred.2", "pred.1", "pred.4", "pred.5", "pred.6", "pred.rf")], na.rm = TRUE)
all_pred$avg_lwr <- rowMeans(all_pred[, c("lwr.2", "lwr.1", "lwr.4", "lwr.5", "lwr.6")], na.rm = TRUE)
all_pred$avg_upr <- rowMeans(all_pred[, c("upr.2", "upr.1", "upr.4", "upr.5", "upr.6")], na.rm = TRUE)
```

```{r, include = FALSE}
# Define weights: .rf columns have weight 1.25, all others have weight 1
weights_pred <- c(1.02, 1.04, 1, 0.9, 1.01, 1.05)  # Weights for pred.2, pred.1, pred.4, pred.5, pred.6, pred.rf
weights_lwr <- c(1.02, 1.04, 1, 0.9, 1.01)         # Weights for lwr.2, lwr.1, lwr.4, lwr.5, lwr.6
weights_upr <- c(1.02, 1.04, 1, 0.9, 1.01)       # Weights for upr.2, upr.1, upr.4, upr.5, upr.6

# Weighted average for predictions
all_pred$avg_pred_w <- rowSums(all_pred[, c("pred.2", "pred.1", "pred.4", "pred.5", "pred.6", "pred.rf")] * weights_pred, na.rm = TRUE) /
                     rowSums(!is.na(all_pred[, c("pred.2", "pred.1", "pred.4", "pred.5", "pred.6", "pred.rf")]) * weights_pred)

# Weighted average for lower bounds
all_pred$avg_lwr_w <- rowSums(all_pred[, c("lwr.2", "lwr.1", "lwr.4", "lwr.5", "lwr.6")] * weights_lwr, na.rm = TRUE) /
                    rowSums(!is.na(all_pred[, c("lwr.2", "lwr.1", "lwr.4", "lwr.5", "lwr.6")]) * weights_lwr)

# Weighted average for upper bounds
all_pred$avg_upr_w <- rowSums(all_pred[, c("upr.2", "upr.1", "upr.4", "upr.5", "upr.6")] * weights_upr, na.rm = TRUE) /
                    rowSums(!is.na(all_pred[, c("upr.2", "upr.1", "upr.4", "upr.5", "upr.6")]) * weights_upr)

```

```{r}
write.csv(all_pred, "predictions.csv", row.names = FALSE)

```


```{r, include = FALSE}
# calculate winner
ec <- read_csv("corrected_ec_1948_2024.csv")

all_pred <- all_pred %>%
  mutate(year = 2024)

ec2024 <- ec %>% filter(year == 2024)

ec2024$state[ec2024$state == "District Of Columbia"] <- "District of Columbia"

all_pred <- all_pred %>% 
  left_join(ec2024, by = "state") %>%
  mutate(winner = ifelse(avg_pred_w > 50, "D", "R"))

outcome <- all_pred %>%
  group_by(winner) %>%
  summarize(electoral_votes = sum(electors))
```

Based on my final ensemble model, I officially predict that Democrat Vice President Kamala Harris will win the 2024 Presidential Election with **303** electoral votes, defeating Republican former President Donald Trump, who I predict will win **235** electoral votes. My model predicts that the 2024 election will be a repeat of the 2020 election, with Harris winning every state Biden won in 2020, including the swing states of Wisconsin, Michigan, Pennsylvania, Georgia, Nevada, and Arizona. Her predicted vote shares, compared to Biden’s, are shown below.


```{r, echo = FALSE, warning = FALSE, message = FALSE}
# final prediction map

all_pred$prediction_fill <- all_pred$avg_pred_w
all_pred$prediction_fill[all_pred$state == "District of Columbia"] <- 80

all_pred <- all_pred %>%
  mutate(across(where(is.numeric), ~ round(., 2)))

# Read US hexgrid data. 
us_hexgrid <- read_sf("us_states_hexgrid.geojson.json") |> 
  mutate(google_name = gsub(" \\(United States\\)", "", google_name))

# Merge state predictions with hexgrid data.
map2 <- us_hexgrid |> 
  left_join(all_pred, by = c("google_name" = "state"))

g3 <- ggplot(data = map2) +
  geom_sf(aes(fill = prediction_fill)) + 
  geom_sf_text(aes(label = iso3166_2,
                   text = paste(
                     google_name,
                     '<br>Predicted Harris 2-P Vote:', avg_pred_w,'%',
                     '<br>2020 Biden 2-P Vote:', D_pv2p,'%',
                     '<br>Electoral Votes:', electors
                   )),
               color = "black", size = 3, alpha = 0.6) + 
  scale_fill_gradient2(low = "red", mid = "white", high = "navyblue", midpoint = 50, 
                       breaks = c(20, 35, 50, 65, 80), 
                       limits = c(20, 80),
                       name = "Harris (D) Predicted Two-Party Vote Share") +
  labs(title = "Final 2024 Presidential Election Prediction") + 
  theme_void() +
  theme(legend.position = "none") + 
  theme(plot.title = element_text(face = "bold"))

ggplotly(g3, tooltip = "text")
```

As always, predictions have uncertainty. Even though I predict a Harris victory, it is a narrow victory, and my model explicitly shows below that Harris or Trump could either eke out slim wins, or be victorious by large electoral college margins. 

```{r, echo = FALSE, warning = FALSE, message = FALSE}
# state prediction intervals

g4 <- ggplot(all_pred, aes(x = avg_pred_w, y = reorder(state, avg_pred_w), 
                       fill = prediction_fill)) + 
  geom_col(
    aes(text = paste(
             state,
             '<br>Predicted Harris 2-P Vote:', avg_pred_w,'%',
             '<br>Lower Bound:', avg_lwr_w,'%',
             '<br>Upper Bound:', avg_upr_w,'%'
           ))
    ) + 
  geom_errorbar(aes(xmin = avg_lwr_w, xmax = avg_upr_w), 
                width = 0.2, color = "black") + 
  scale_fill_gradient2(low = "red", mid = "white", high = "navyblue", 
                       midpoint = 50, breaks = c(30, 40, 50, 60, 70), 
                       limits = c(20, 80), name = "") +  
  labs(x = "Harris (D) Predicted Two-Party Vote Share",
       y = "State",
       title = "Final Model Predictions") +
  geom_vline(xintercept = 50, linetype = "dotted") +
  theme(panel.background = element_rect(fill = "white"),
        plot.title = element_text(hjust = 0, size = 14),
        axis.text.y = element_text(size = 5),
        panel.grid.major = element_line(color = "lightgray", size = 0.3),
        panel.grid.minor = element_line(color = "lightgray", size = 0.2),
        plot.title.position = "plot") + 
  theme(plot.title = element_text(face = "bold"))

ggplotly(g4, tooltip = "text") 
```

And with that, this concludes my series of prediction blogs. Tomorrow, we will find out how my forecast fares, and this time next week, we shall hopefully know who will be the 47th President of the United States of America.